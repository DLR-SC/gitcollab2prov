# Copyright (c) 2019 German Aerospace Center (DLR/SC).
# All rights reserved.
#
# This file is part of gitlab2prov.
# gitlab2prov is licensed under the terms of the MIT License.
# SPDX short Identifier: MIT
#
# You may obtain a copy of the License at:
# https://opensource.org/licenses/MIT
#
# A command line tool to extract provenance data (PROV W3C)
# from GitLab hosted repositories aswell as
# to store the extracted data in a Neo4J database.
#
# code-author: Claas de Boer <claas.deboer@dlr.de>


# standard lib imports
from collections import defaultdict, deque
# extern imports
import prov.model as pm
from prov.constants import PROV_LABEL, PROV_ROLE, PROV_TYPE
# project imports
from gl2p.helpers import namify, idfy
from gl2p.commons import FileStatus


class Translator:

    def __init__(self):
        self.alias = dict()

    def run(self, container):
        # -- init --
        document = pm.ProvDocument()
        document.set_default_namespace("gl2p:")
        self.alias = self._compute_alias_lookup(container.files)
        entities = set()  # store entities to avoid referencing non-existing ones

        # -- fill --
        # (1.0) -- files --
        for f in container.files:
            # -- find original file name --
            stem_file = "file-{}".format(self._find_stem_file(f))
            stem_file_id = idfy(stem_file)
            file_name = "file-{}_commit-{}".format(namify(f.new_path), f.commit_sha)
            file_id = idfy(file_name)

            # -- create entity for file -- 
            document.entity(identifier=stem_file_id, other_attributes={PROV_TYPE: "file", "name": stem_file, "path": f.new_path})
            entities.add(stem_file_id)
            document.entity(identifier=file_id, other_attributes={PROV_TYPE: "file", "name": file_name, "path": f.new_path})
            entities.add(file_id)
            # -- connect file to its origin --
            document.specializationOf(specificEntity=file_id, generalEntity=stem_file_id)
            # -- attribute file to its author --
            agent = "user-{}".format(namify(container.get_commit(f.commit_sha).author.name))
            document.wasAttributedTo(entity=file_id, agent=agent)

        # (2.0) -- commits --
        for commit in container.commits():
            # -- add activity for each commit --
            identifier = "commit-{}".format(commit.sha)
            document.activity(identifier=identifier, other_attributes={PROV_LABEL: commit.msg, PROV_TYPE: "commit"})
            # -- add time information to activity --
            document.wasStartedBy(activity=identifier, time=commit.time.authored, identifier=hash(identifier))
            document.wasEndedBy(activity=identifier, time=commit.time.committed, identifier=hash(identifier))
            # -- connect activity to parents --
            for parent in commit.parents:
                parent = "commit-{}".format(parent)
                document.wasInformedBy(informed=identifier, informant=parent, identifier=hash(identifier))

            # (2.1) -- files in commits --
            for f in commit.files:
                f_id = namify("file-{}_commit-{}".format(namify(f.new_path), commit.sha))
                # -- file/file version was generated by activity --
                document.wasGeneratedBy(entity=f_id, activity=identifier, time=commit.time.authored)
                if f.status == FileStatus.MODIFIED:
                    for parent in commit.parents:
                        usedEntity = "file-{}_commit-{}".format(namify(f.old_path), parent)
                        # -- check whether a file version exists or not --
                        # -- if version does not exist, skip --
                        if usedEntity not in entities:
                            continue
                        # -- mark file as used by activity --
                        document.used(activity=identifier, entity=usedEntity, time=commit.time.authored)
                        # -- relate file to parent file snapshot --
                        document.wasDerivedFrom(generatedEntity=f_id, usedEntity=usedEntity, activity=identifier)
                if f.status == FileStatus.DELETED:
                    # -- file/file version was deleted by activity --
                    document.wasInvalidatedBy(entity=f_id, activity=identifier, time=commit.time.authored)

        # (3.0) -- agents --
        for commit in container.commits():
            identifier = "commit-{}".format(commit.sha)
            author = "user-{}".format(namify(commit.author.name))
            committer = "user-{}".format(namify(commit.committer.name))
            # -- create agents --
            document.agent(identifier=author, other_attributes={"name": commit.author.name, "email": commit.author.email, PROV_TYPE: "committer"})
            document.agent(identifier=committer, other_attributes={"name": commit.committer.name, "email": commit.author.email, PROV_TYPE: "committer"})
            # -- associate agents with activities --
            document.wasAssociatedWith(activity=identifier, agent=author, identifier=hash(identifier+author), other_attributes={PROV_ROLE: "author"})
            document.wasAssociatedWith(activity=identifier, agent=committer, identifier=hash(identifier+committer), other_attributes={PROV_ROLE: "committer"})

        # -- remove possible duplicates --
        document = document.unified()
        return document

    def _find_stem_file(self, f):
        # get original file name for a file f
        return self.alias.get(f.new_path)

    def _compute_alias_lookup(self, files):
        names = defaultdict(set)
        tracks = []
        lookup = dict()
        files = set(files)

        # -- build name lookup --
        for f in files:
            names[f.old_path].add(f.new_path)
        
        # -- build file tracks by bfs --
        # for each name, track as far forth as possible
        for f in files:
            queue, visited = deque([f.new_path]), list()
            while queue:
                active = queue.popleft()
                visited.append(active)
                for node in names.get(active, []):
                    if node in visited:
                        continue
                    queue.append(node)
            tracks.append(visited)

        # -- build lookup from file tracks --
        # choose longest tracks as candidates
        for f in files:
            track = sorted(filter(lambda l: f.new_path in l, tracks), key=len)[-1]
            root, *n = track
            lookup[root] = root
            for name in n:
                lookup[name] = root
        return lookup
